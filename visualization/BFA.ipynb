{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "0. 设置基本参数\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy,sys,time,torch\n",
    "sys.path.append('projects/RG-DFKD')\n",
    "sys.path\n",
    "import registry,datafree\n",
    "from BFA.quantization import quan_Conv2d, quan_Linear\n",
    "from BFA.quan_utils import Fp2QuModel, SimpleOptQuanModel\n",
    "from BFA.BFA import BFA\n",
    "print(registry.__file__)\n",
    "print(datafree.__file__)\n",
    "'''运行参数'''\n",
    "model_names=['resnet34','vgg11','wrn40_2']  # 模型\n",
    "dataset='cifar10'  # 数据集\n",
    "data_root='datasets/' #数据集路径\n",
    "attack_sample_size=128  # 用于攻击的数据批次规模\n",
    "independent_run_times=5 # 独立执行BFA的次数\n",
    "n_iter=int(20)  # 攻击造成的比特翻转数量\n",
    "k_top=int(10)  \n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "1. 加载数据和模型\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''加载真实数据集'''\n",
    "num_classes, ori_dataset, val_dataset = registry.get_dataset(name=dataset, data_root=data_root)\n",
    "train_loader = torch.utils.data.DataLoader(ori_dataset,batch_size=attack_sample_size, shuffle=True,num_workers=0, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,batch_size=attack_sample_size, shuffle=False,num_workers=0, pin_memory=True)\n",
    "print('train samples {}  val samples {}'.format(len(train_loader.dataset),len(val_loader.dataset)))\n",
    "'''加载模型并转化为可供攻击的8比特量化模型'''\n",
    "def get_qu_model(model_name,num_classes):\n",
    "    model = registry.get_model(model_name, num_classes=num_classes, pretrained=True).eval()\n",
    "    model.load_state_dict(torch.load('../checkpoints/pretrained/%s_%s.pth'%(dataset, model_name), map_location='cpu')['state_dict'])\n",
    "    model_qu=model\n",
    "    model_qu=Fp2QuModel(model_qu)\n",
    "    model_qu=SimpleOptQuanModel(model_qu)\n",
    "    for m in model_qu.modules():\n",
    "        if isinstance(m, quan_Conv2d) or isinstance(m, quan_Linear):\n",
    "            m.__reset_weight__()\n",
    "    return model_qu\n",
    "models=[]\n",
    "for name in model_names:\n",
    "    models.append(get_qu_model(name,num_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "2. 测试初始模型精度\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''测试原始模型和转换后的模型的精度'''\n",
    "evaluator = datafree.evaluators.classification_evaluator(val_loader)\n",
    "for model in models:\n",
    "    model_qu=model.cuda()\n",
    "    model_qu.eval()\n",
    "    result_qu=evaluator(model_qu,device=int(0))\n",
    "    print('{}: top1={:.4f}  top5={:.4f}  loss={:.4f}'.format(type(model_qu),result_qu['Acc'][0],result_qu['Acc'][1],result_qu['Loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 攻击迭代\n",
    "def perform_attack(attacker, model, train_loader, evaluator,N_iter):\n",
    "    model.eval()\n",
    "    # attempt to use the training data to conduct BFA\n",
    "    if type(train_loader)==torch.utils.data.dataloader.DataLoader:\n",
    "        for _, (data, target) in enumerate(train_loader):\n",
    "            target = target.cuda()\n",
    "            data = data.cuda()\n",
    "            # Override the target to prevent label leaking\n",
    "            _, target = model(data).data.max(1)\n",
    "            break\n",
    "    else:\n",
    "        data=train_loader.sample()\n",
    "        data = data.cuda()\n",
    "        _, target = model(data).data.max(1)\n",
    "        target = target.cuda()\n",
    "    for i_iter in range(N_iter):\n",
    "        attacker.progressive_bit_search(model, data, target)\n",
    "        if i_iter==N_iter-1:\n",
    "            result= evaluator(model, device=0)\n",
    "            (val_acc_top1, val_acc_top5), val_loss=result['Acc'], result['Loss']\n",
    "            print('      bit flips: {:.0f} Attacked model: top1={:.3f} top5={:.3f} loss={:.3f}'.format(attacker.bit_counter,val_acc_top1, val_acc_top5,val_loss))\n",
    "    return val_acc_top1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "3. 验证使用不同数据时BFA效果\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "    3.1 真实数据\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacked_top1={}\n",
    "for (index,name) in enumerate(model_names):\n",
    "    attacked_top1[name]={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('==> Data source: real samples')\n",
    "for (index,name) in enumerate(model_names):\n",
    "    print('   ==> model: {}'.format(name))\n",
    "    attacked_top1[name]['real']=[]\n",
    "    model_qu=models[index]\n",
    "    for _ in range(independent_run_times):\n",
    "        net=copy.deepcopy(model_qu)\n",
    "        attacker = BFA(criterion, k_top)\n",
    "        attacked_top1[name]['real'].append(perform_attack(attacker, net, train_loader, evaluator, n_iter))\n",
    "        del net,attacker\n",
    "print(attacked_top1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "    3.2 随机数据\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造10000条随机数据\n",
    "import torch.utils.data as Data\n",
    "samples=torch.rand((10000,3,32,32))\n",
    "targets=torch.ones((10000,),dtype=torch.int)\n",
    "targets=targets.tolist()\n",
    "targets=torch.tensor(targets)\n",
    "rand_train_dataset=Data.TensorDataset(samples,targets)\n",
    "rand_train_loader=Data.DataLoader(dataset = rand_train_dataset,batch_size = attack_sample_size,shuffle = True)\n",
    "\n",
    "print('==> Data source: Random samples')\n",
    "for (index,name) in enumerate(model_names):\n",
    "    print('   ==> model: {}'.format(name))\n",
    "    model_qu=models[index]\n",
    "    attacked_top1[name]['random']=[]\n",
    "    for _ in range(independent_run_times):\n",
    "        net=copy.deepcopy(model_qu)\n",
    "        attacker = BFA(criterion, k_top)\n",
    "        attacked_top1[name]['random'].append(perform_attack(attacker, net, rand_train_loader, evaluator, n_iter))\n",
    "        del net,attacker\n",
    "    \n",
    "del samples,targets,rand_train_dataset,rand_train_loader\n",
    "print(attacked_top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成器工具\n",
    "from torchvision import transforms\n",
    "from kornia import augmentation\n",
    "\n",
    "class SynthesizerForSamples():\n",
    "    def __init__(self,generator,nz,bs,normalizer):\n",
    "        self.generator=generator\n",
    "        self.nz=nz\n",
    "        self.bs=bs\n",
    "        self.img_size=(3,32,32)\n",
    "        self.aug = transforms.Compose([ \n",
    "                augmentation.RandomCrop(size=[self.img_size[-2], self.img_size[-1]], padding=4),\n",
    "                augmentation.RandomHorizontalFlip(),\n",
    "                normalizer,\n",
    "            ])\n",
    "    def sample(self):\n",
    "        self.generator.eval()\n",
    "        z = torch.randn(size=(self.bs, self.nz)).cuda()\n",
    "        input=self.generator(z)\n",
    "        inputs_aug = self.aug(input)\n",
    "        return inputs_aug\n",
    "\n",
    "def addition_fusion(tensor1, tensor2):\n",
    "    return (tensor1 + tensor2)/2\n",
    "\n",
    "class AutoFusion(torch.nn.Module):\n",
    "    def __init__(self,generator_original,generator_reuse,decoder):\n",
    "        super(AutoFusion, self).__init__()\n",
    "        self.generator = generator_original\n",
    "        self.generator_reuse = generator_reuse\n",
    "        self.decoder=decoder\n",
    "    \n",
    "    def forward(self,z):\n",
    "        out1=self.generator(z)\n",
    "        out2=self.generator_reuse(z) \n",
    "        out=addition_fusion(out1,out2)\n",
    "        out=self.decoder(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "    3.3 用于预训练生成器的参数\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "    3.3 reuse_waiver\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1=datafree.models.generator.Generator(nz=256, ngf=64, img_size=32, nc=3)\n",
    "g2=torch.load('run/anew-cifar10-resnet34-resnet18/gan_abandon.pth')\n",
    "d=torch.load('run/anew-cifar10-resnet34-resnet18/decoder.pth')\n",
    "generator=AutoFusion(g1,g2,d)\n",
    "normalizer = datafree.utils.Normalizer(**registry.NORMALIZE_DICT[dataset])\n",
    "generator=generator.cuda()\n",
    "synthesizer=SynthesizerForSamples(generator,256,attack_sample_size,normalizer)\n",
    "\n",
    "print('==> Data source: Reuse Waiver generative network')\n",
    "for (index,name) in enumerate(model_names):\n",
    "    print('   ==> model: {}'.format(name))\n",
    "    model_qu=models[index]\n",
    "    attacked_top1[name]['reuse_waiver']=[]\n",
    "    for _ in range(independent_run_times):\n",
    "        net=copy.deepcopy(model_qu)\n",
    "        attacker = BFA(criterion, k_top)\n",
    "        attacked_top1[name]['reuse_waiver'].append(perform_attack(attacker, net, synthesizer, evaluator, n_iter))\n",
    "        del net,attacker\n",
    "    \n",
    "del g1,g2,d,generator,normalizer,synthesizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "    3.4 reuse\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1=datafree.models.generator.Generator(nz=256, ngf=64, img_size=32, nc=3)\n",
    "g2=torch.load('run/anew-cifar10-resnet34-resnet18/gan_reuse.pth')\n",
    "d=torch.load('run/anew-cifar10-resnet34-resnet18/decoder.pth')\n",
    "generator=AutoFusion(g1,g2,d)\n",
    "normalizer = datafree.utils.Normalizer(**registry.NORMALIZE_DICT[dataset])\n",
    "generator=generator.cuda()\n",
    "synthesizer=SynthesizerForSamples(generator,256,attack_sample_size,normalizer)\n",
    "\n",
    "print('==> Data source: Reusable generative network')\n",
    "for (index,name) in enumerate(model_names):\n",
    "    print('   ==> model: {}'.format(name))\n",
    "    model_qu=models[index]\n",
    "    attacked_top1[name]['reuse']=[]\n",
    "    for _ in range(independent_run_times):\n",
    "        net=copy.deepcopy(model_qu)\n",
    "        attacker = BFA(criterion, k_top)\n",
    "        attacked_top1[name]['reuse'].append(perform_attack(attacker, net, synthesizer, evaluator, n_iter))\n",
    "        del net,attacker\n",
    "    \n",
    "del g1,g2,d,generator,normalizer,synthesizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5 reuse_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reuse_all直接使用运行中保存的张量即可，不必再另行构造生成器\n",
    "samples=torch.load('run/anew-cifar10-resnet34-resnet18/synthetic.pth')\n",
    "targets=torch.ones((256,),dtype=torch.int)\n",
    "targets=targets.tolist()\n",
    "targets=torch.tensor(targets)\n",
    "all_train_dataset=Data.TensorDataset(samples,targets)\n",
    "all_train_loader=Data.DataLoader(dataset = all_train_dataset,batch_size = attack_sample_size,shuffle = True)\n",
    "\n",
    "print('==> Data source: Reuse all')\n",
    "for (index,name) in enumerate(model_names):\n",
    "    print('   ==> model: {}'.format(name))\n",
    "    model_qu=models[index]\n",
    "    attacked_top1[name]['reuse_all']=[]\n",
    "    for _ in range(independent_run_times):\n",
    "        net=copy.deepcopy(model_qu)\n",
    "        attacker = BFA(criterion, k_top)\n",
    "        attacked_top1[name]['reuse_all'].append(perform_attack(attacker, net, all_train_loader, evaluator, n_iter))\n",
    "        del net,attacker\n",
    "    \n",
    "del samples,targets,all_train_dataset,all_train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 存储CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv,os\n",
    "file_name='bfa.csv'\n",
    "if os.path.exists(file_name):\n",
    "    os.remove(file_name)\n",
    "\n",
    "attacked_acc=copy.deepcopy(attacked_top1)\n",
    "with open(file_name, \"a\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    order=[]\n",
    "    for name in model_names:\n",
    "        \n",
    "        order.append(name+'-real')\n",
    "        attacked_acc[name]['real'].insert(0,name+'-real')\n",
    "        csv_writer.writerow(attacked_acc[name]['real'])\n",
    "        \n",
    "        order.append(name+'-random')\n",
    "        attacked_acc[name]['random'].insert(0,name+'-random')\n",
    "        csv_writer.writerow(attacked_acc[name]['random'])\n",
    "        \n",
    "        order.append(name+'-reuse')\n",
    "        attacked_acc[name]['reuse'].insert(0,name+'-reuse')\n",
    "        csv_writer.writerow(attacked_acc[name]['reuse'])\n",
    "        \n",
    "        order.append(name+'-reuse_waiver')\n",
    "        attacked_acc[name]['reuse_waiver'].insert(0,name+'-reuse_waiver')\n",
    "        csv_writer.writerow(attacked_acc[name]['reuse_waiver'])\n",
    "        \n",
    "        order.append(name+'-reuse_all')\n",
    "        attacked_acc[name]['reuse_all'].insert(0,name+'-reuse_all')\n",
    "        csv_writer.writerow(attacked_acc[name]['reuse_all'])\n",
    "    f.close\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
